{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a4f928-50aa-497a-9d8b-e63d9b8abeb6",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "In this part we find the **OPcode Repeat Frequency** as feature.\n",
    "For this purpose, we must first find the **pattern** of opcodes in assembly codes.\n",
    "We use **Regex** or **Regular Expression** to explain this pattern.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a7363-275f-49dd-8308-0ef665f7388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from operator import add\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.master(\"master[*]\").appName(\"MalwareClassification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8e844-2339-47f0-b45d-394e59ef1b39",
   "metadata": {},
   "source": [
    "# Regex\n",
    "\n",
    "The opcodes pattern used in this dataset is like:\n",
    "\n",
    "    .Segment 0xXXXXXXX (some hex number)\t(some spaces) \t\topcode (some operand)\n",
    "We used the Regex `OPCODE_PATTERN = (r'([\\s])([A-F0-9]{2})([\\s]+)([a-z]+)([\\s+])') `\tto get the last byte of Hex number in front of segments and the space between last byte and opcode and in the end find the opcode.\n",
    "Further we used the Regex `JUST_OPCODE = (r'([a-z]+)')`to find the opcode in the pattern explained above.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced38961-e6bf-466b-92f0-ba0dce2c4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPCODE_PATTERN = (r'([\\s])([A-F0-9]{2})([\\s]+)([a-z]+)([\\s+])')\n",
    "JUST_OPCODE = (r'([a-z]+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebfc452-6a8e-4c61-a443-bed058449f4b",
   "metadata": {},
   "source": [
    "## Find the name list of files\n",
    "\n",
    "In the codes below we find the name of all assembly files in dataset. We used **trainLabels.csv** provided by Kaggle to make a list of name that contains the name of all files in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbd4131-dbaf-4b2f-b889-5f9a947c5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmFolderPath = './train/asm'\n",
    "trainFilenamesArray = np.genfromtxt('trainLabels.csv', delimiter=\",\", dtype=None, encoding=None)\n",
    "trainFilenamesArray = trainFilenamesArray[1:].tolist()\n",
    "trainFilenamesList = [item[0] for item in trainFilenamesArray]\n",
    "trainFilenamesList = [item.replace('\"', \"\") for item in trainFilenamesList]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac56aa-fc4f-42cf-8a32-3009f253bfdd",
   "metadata": {},
   "source": [
    "## Create a feature file for every ASM file\n",
    "\n",
    "In code below we created a **CSV** file for every single ASM file in dataset. This CSV file contains column named **OPcodes** and a column named **count** that shows the number of how many times an opcode appeared in code.\n",
    "then the function **featureExtraction** save this CSV file with the same name of ASM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecb10a4-1050-43ba-8662-49b8db70c3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "featuresFolderPath = './features'\n",
    "\n",
    "def featureExtraction(trainNameList):\n",
    "    for Name in trainNameList:\n",
    "        fileName = asmFolderPath + '/' + Name + '.asm'\n",
    "        textDf = spark.read.text(fileName)\n",
    "        resaultDf = textDf.withColumn('OPcodes', regexp_extract(col('value'), OPCODE_PATTERN, 0))\n",
    "        resaultDf = resaultDf.withColumn('OPcodes', regexp_extract(col('OPcodes'), JUST_OPCODE, 0))\n",
    "        resaultDf = resaultDf.where(func.ltrim(func.col(\"OPcodes\")) != \"\")\n",
    "        resaultDf = resaultDf.groupBy(\"OPcodes\").count().orderBy(func.col(\"count\").desc())\n",
    "        resaultDf.toPandas().to_csv(f'{featuresFolderPath}/{Name}.csv')\n",
    "        \n",
    "featureExtraction(trainFilenamesList)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
